{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "861af33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Section: Requirements\n",
      "- Possess strong coding skills that you are ready to turn into industry-ready coding skills\n",
      "- Pursuing a degree in Computer Science or other STEM degrees\n",
      "- Strong preference for students who are recently graduated or nearing graduation\n",
      "- Excited to learn new languages and technologies\n",
      "- Willing to dive in and learn by doing\n",
      "- Ready to work with others to solve hard problems\n",
      "- Possess a startup personality: smart, ethical, friendly, hard-working and proactive\n",
      "- Excited to work with products that have close interactions with customers\n",
      "\n",
      "Section: Responsibilities\n",
      "- Contribute deeply to our real production systems - billions of daily requests, 80+ PBs of data, millions of anonymous people records, and powerful web applications to make it all accessible and intuitive\n",
      "- Learn about the business and engineering practices at LiveRamp\n",
      "- Prove yourself and earn the responsibilities of a full-time engineer\n",
      "\n",
      "Section: Desired Qualifications\n",
      "- Experience with Agile software development\n",
      "- Experience developing user interfaces with the React framework\n",
      "- Experience with Ruby on Rails or Node.js\n",
      "- Experience with TypeScript and Express.js\n",
      "\n",
      "Section: Requirements\n",
      "- Degree path in engineering, computer science or a related technical field\n",
      "- Good Computer Science fundamentals in object-oriented design and data structures\n",
      "- Experience in cloud microservice and development in Python and/or Go\n",
      "- Effective communication skills at building relationships across teams\n",
      "- Taking initiative and self-starter, as part of a team\n",
      "\n",
      "Section: Responsibilities\n",
      "- Design, implement, test, and deploy microservices in a CICD pipeline that provide REST interfaces to mobile apps and other microservices\n",
      "- Work with architects and product owners to translate requirements into the next set of cloud functionality\n",
      "- Write well-designed and fully tested production-quality code\n",
      "\n",
      "Section: Desired Qualifications\n",
      "- Hone your cloud microservice development skills on an exciting project using innovative technologies\n",
      "- Design, implement and test REST APIs\n",
      "- Work within a modern agile software engineering team\n",
      "- Gain experience with the tools and processes used to build high-quality software, including automated testing, peer code reviews\n",
      "- Learn to balance the immediate deliverables for a project with the long-term platform vision\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import time\n",
    "\n",
    "urls = [  # Replace with your actual 1200 URLs\n",
    "    \"https://simplify.jobs/p/8c19aaed-2fe5-4561-95d0-e1c86fc18eae?utm_source=GHList\",\"https://simplify.jobs/p/65190a0d-1fe9-4aca-abc6-489c7f9dbcf3?utm_source=GHList\"\n",
    "\n",
    "    # more URLs...\n",
    "]\n",
    "\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "output_file = \"simplify_scraped_data.csv\"\n",
    "\n",
    "with open(output_file, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"URL\", \"Job Title\", \"Company\", \"Description\"])  # Add more fields as needed\n",
    "\n",
    "    for url in urls:\n",
    "        try:\n",
    "            res = requests.get(url, headers=headers)\n",
    "            soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "\n",
    "            # Adapt selectors based on actual structure\n",
    "\n",
    "# Replace this with your actual HTML content\n",
    "            sections = soup.find_all(\"div\", class_=\"text-left\")\n",
    "            for section in sections:\n",
    "                # Extract section title (from the inner div with class 'text-base font-bold...')\n",
    "                title_div = section.find(\"div\", class_=\"mt-3 text-base font-bold text-secondary-400\")\n",
    "                if not title_div:\n",
    "                    continue\n",
    "                title = title_div.get_text(strip=True)\n",
    "\n",
    "                print(f\"Section: {title}\")\n",
    "\n",
    "                # Extract each <li> in the section\n",
    "                items = section.find_all(\"li\")\n",
    "                for li in items:\n",
    "                    print(f\"- {li.get_text(strip=True)}\")\n",
    "                print()  # Blank line between sections\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error scraping {url}: {e}\")\n",
    "\n",
    "        time.sleep(0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e747a3c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'soup' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbs4\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BeautifulSoup\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Replace this with your actual HTML content\u001b[39;00m\n\u001b[32m      4\u001b[39m \n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Find all the divs with class 'text-left'\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m sections = \u001b[43msoup\u001b[49m.find_all(\u001b[33m\"\u001b[39m\u001b[33mdiv\u001b[39m\u001b[33m\"\u001b[39m, class_=\u001b[33m\"\u001b[39m\u001b[33mtext-left\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m section \u001b[38;5;129;01min\u001b[39;00m sections:\n\u001b[32m      9\u001b[39m     \u001b[38;5;66;03m# Extract section title (from the inner div with class 'text-base font-bold...')\u001b[39;00m\n\u001b[32m     10\u001b[39m     title_div = section.find(\u001b[33m\"\u001b[39m\u001b[33mdiv\u001b[39m\u001b[33m\"\u001b[39m, class_=\u001b[33m\"\u001b[39m\u001b[33mmt-3 text-base font-bold text-secondary-400\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'soup' is not defined"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
